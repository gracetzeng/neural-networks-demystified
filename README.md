# neural-networks-demystified
My personal notes and code while following Welch Lab's neural network video series! This series provides an intuitive and hands-on introduction to the foundations of neural networks, and I had a fun time deriving equations using my calculus knowledge, implementing concepts, and gaining a deeper (no pun intended) understanding of neural networks.

The main notebook file is divided into 7 parts, as is the series. Each part includes my notes on the episodes and their corresponding code implementations. I used Python along with NumPy for array manipulation and matrix calculations, matplotlib to visualize functions and the model, and SciPy for training.

Cool things I learned!
- The sigmoid activation function
- Sending data through a neural network (forward propogation)
- Gradient descent and how to derive its equations
- Weight adjustment (backpropogation)
- Gradient checking
- Reducing overfitting

You can watch the video series here --> https://www.youtube.com/playlist?list=PLiaHhY2iBX9hdHaRr6b7XevZtgZRa1PoU
